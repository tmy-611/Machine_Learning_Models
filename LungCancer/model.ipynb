{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Python and Spark to work on this dataset.\n",
    "Link to the dataset: https://www.kaggle.com/datasets/humairmunir/lung-cancer-risk-dataset?resource=download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master='local')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "          .appName(\"Lung Cancer Prediction\") \\\n",
    "          .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "          .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load and read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('lungcancer.csv', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use LUNG_CANCER column as target variable in model prediction.\n",
    "- The remain columns will be considered as features in model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Engineering: In this section, I go through these tasks.\n",
    "    - Define numerical/categorical columns. Since label column is also a categorical columns, we include it in the categorical columns to compute the next task.\n",
    "    - StringIndexing all categorical columns\n",
    "    - Remove indexed label columns to prepare for OneHotEncoding task.\n",
    "    - OneHotEncoding all indexed columns.\n",
    "    - Remove unnecessary columns and Re-arrange the dataframe\n",
    "    - VectorAsembling to map all features into FEATURES column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical/categorical columns\n",
    "numerical_cols = 'AGE'\n",
    "categorical_cols = df.columns\n",
    "categorical_cols.remove('AGE') # remove numerical column\n",
    "\n",
    "print(\"Numerical column: \" + numerical_cols)\n",
    "print(\"Categorical columns: \")\n",
    "print(*categorical_cols, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringIndexing\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=\"indexed_\"+column) for column in categorical_cols]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "# fit and transform the pipeline\n",
    "indexed_df = pipeline.fit(df).transform(df)\n",
    "indexed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove target variable \n",
    "categorical_cols.remove('LUNG_CANCER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding\n",
    "encoders = [OneHotEncoder(inputCol=\"indexed_\"+column, outputCol=\"encoded_\"+column) for column in categorical_cols]\n",
    "pipeline = Pipeline(stages=encoders)\n",
    "\n",
    "# fit and transform the pipeline\n",
    "encoded_df = pipeline.fit(indexed_df).transform(indexed_df)\n",
    "encoded_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indexed columns \n",
    "import re\n",
    "\n",
    "# Define the pattern \n",
    "pattern = re.compile(r'^indexed_')\n",
    "\n",
    "# Subtract the set of columns that match the pattern\n",
    "indexed_columns = [col for col in indexed_df.columns if pattern.match(col)]\n",
    "indexed_columns.remove('indexed_LUNG_CANCER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Re-structure dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "encoded_df = encoded_df.drop(*categorical_cols).drop(*indexed_columns).drop('LUNG_CANCER')\n",
    "\n",
    "# Re-arrange dataframe\n",
    "encoded_df.select('AGE',\n",
    " 'encoded_GENDER',\n",
    " 'encoded_SMOKING',\n",
    " 'encoded_YELLOW_FINGERS',\n",
    " 'encoded_ANXIETY',\n",
    " 'encoded_PEER_PRESSURE',\n",
    " 'encoded_CHRONIC_DISEASE',\n",
    " 'encoded_FATIGUE',\n",
    " 'encoded_ALLERGY',\n",
    " 'encoded_WHEEZING',\n",
    " 'encoded_ALCOHOL_CONSUMING',\n",
    " 'encoded_COUGHING',\n",
    " 'encoded_SHORTNESS_OF_BREATH',\n",
    " 'encoded_SWALLOWING_DIFFICULTY',\n",
    " 'encoded_CHEST_PAIN',\n",
    " 'indexed_LUNG_CANCER').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indexed columns \n",
    "import re\n",
    "\n",
    "# Define the pattern \n",
    "pattern = re.compile(r'^encoded_')\n",
    "\n",
    "# Subtract the set of columns that match the pattern\n",
    "encoded_columns = [col for col in encoded_df.columns if pattern.match(col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Ensembling\n",
    "# features\n",
    "features = []\n",
    "features.append('AGE')\n",
    "for i in encoded_columns:\n",
    "    features.append(i)\n",
    "\n",
    "assembler = VectorAssembler(inputCols= features, outputCol=\"FEATURES\")\n",
    "df2 = assembler.transform(encoded_df)\n",
    "df2 = df2.withColumnRenamed('indexed_LUNG_CANCER', 'LABEL').select('FEATURES','LABEL')\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train Split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df2.randomSplit([0.8, 0.2], seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol='FEATURES', labelCol='LABEL')\n",
    "rf = RandomForestClassifier(featuresCol='FEATURES', labelCol='LABEL')\n",
    "lr = LogisticRegression(featuresCol='FEATURES', labelCol='LABEL')\n",
    "gbt = GBTClassifier(featuresCol='FEATURES', labelCol='LABEL', maxIter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"LABEL\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Param grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [2, 3, 4, 5]) \\\n",
    "    .build()\n",
    "\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "lr_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "gbt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [2, 5, 10]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree Cross-Validation with Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv = CrossValidator(estimator=dt, estimatorParamMaps=dt_param_grid, evaluator=evaluator, numFolds=6)\n",
    "dt_cv_model = dt_cv.fit(train_data)\n",
    "dt_predictions = dt_cv_model.transform(test_data)\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
    "print(f\"Decision Tree Test Accuracy: {dt_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Cross-Validation with Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = CrossValidator(estimator=rf, estimatorParamMaps=rf_param_grid, evaluator=evaluator, numFolds=6)\n",
    "rf_cv_model = rf_cv.fit(train_data)\n",
    "rf_predictions = rf_cv_model.transform(test_data)\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression Cross-Validation with Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv = CrossValidator(estimator=lr, estimatorParamMaps=lr_param_grid, evaluator=evaluator, numFolds=6)\n",
    "lr_cv_model = lr_cv.fit(train_data)\n",
    "lr_predictions = lr_cv_model.transform(test_data)\n",
    "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
    "print(f\"Logistic Regression Test Accuracy: {lr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient-Boosted Trees Cross-Validation with Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_cv = CrossValidator(estimator=gbt, estimatorParamMaps=gbt_param_grid, evaluator=evaluator, numFolds=6)\n",
    "gbt_cv_model = gbt_cv.fit(train_data)\n",
    "gbt_predictions = gbt_cv_model.transform(test_data)\n",
    "gbt_accuracy = evaluator.evaluate(gbt_predictions)\n",
    "print(f\"GBT Test Accuracy: {gbt_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
